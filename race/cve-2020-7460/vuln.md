# CVE-2020-7460

double-fetch (TOCTOU) in freebsd32_copyin_control: kernel first scans user control buffer to compute total length, then later re-reads each cmsg header/data and copies with `copyin`. attacker can change lengths between scans → kernel copies more than allocated mbuf → heap overflow.

## Context / ACID
- syscall: `sendmsg` ancillary control buffer (msghdr->msg_control) is user-supplied — ACID.  
- function: `freebsd32_copyin_control()` first iterates headers (first fetch) to compute `len`, then later `copyin()`s headers+data (second fetch) into an mbuf sized from that first pass.  
- limits: buflen is bounded (<= MCLBYTES), but per-header lengths come from user and are re-read later.

## First thoughts
initial loop looks paranoid — checks for msglen sanity and cumulative length — good. but double-fetches are deadly: if user can change header lengths after the scan, those checks are meaningless.

## Actual trace (short)
- buflen aligned and checked ≤ MCLBYTES.  
- first loop: `copyin(buf + idx, &msglen, sizeof(msglen))` for each header → validates `msglen >= sizeof(cmsghdr)` and `idx + msglen <= buflen` → accumulates `len`.  
- allocate mbuf sized `len`. set `m->m_len = len`.  
- second loop: `copyin(buf, md, sizeof(struct cmsghdr))` → read header again into kernel temp; compute `msglen = *(u_int *)md` and realign.  
- if `msglen > 0` then `copyin(buf, md, msglen)` copies the data following header into mbuf. **this is the second fetch**.  
- attacker races: modify `cmsg_len` in userspace between first and second fetch so second `msglen` is much larger than what was used to size mbuf → `copyin` overruns mbuf → heap overflow.

## Root cause
TOCTOU/double-fetch: code relies on earlier scan of untrusted user buffer to size kernel buffer, then re-reads the same untrusted lengths when copying. attacker-controlled buffer can be changed between reads.

## Exploitability
Practical: attacker controls the msghdr control buffer. race window exists between first scan and subsequent `copyin`s. By swapping in larger `cmsg_len` values, kernel will `copyin` more bytes than mbuf holds → kernel heap overflow, leading to corruption and possible escalation in kernel context. Requires racing or threads in userland to flip the buffer at the right time (feasible).

## Patch
copy once then parse: kernel change copies the entire user control buffer into kernelspace first (single fetch), then parses/copies from that local copy. alternatively, validate and copy each header+data atomically (copy header then copy its data immediately into kernel allocation, not relying on earlier global scan). net effect: no second read of user-controlled lengths.

## Takeaway
double-fetch = deadly. either memcpy the whole user blob into kernel (single trusted copy) or do per-element atomic copy/validate. time-of-check must be the same as time-of-use when dealing with untrusted userspace memory.

